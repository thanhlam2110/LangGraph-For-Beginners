{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef89db0-7187-44ae-b1e3-d1539a78e1ed",
   "metadata": {},
   "source": [
    "## Cách hoạt động:\n",
    "\n",
    "Bạn định nghĩa một hàm Python (get_restaurant_recommendations) với decorator @tool để biến nó thành một tool mà LLM (ChatOpenAI) có thể gọi.\n",
    "\n",
    "Bạn tạo một list các tool, rồi bind tool đó vào LLM bằng .bind_tools().\n",
    "\n",
    "Khi nhận message (\"Recommend some restaurants in Munich.\"), LLM sẽ quyết định (dựa vào prompt và tool description) có nên gọi tool không, và tự động lấy kết quả trả về.\n",
    "\n",
    "Tất cả tool đều nằm local, chạy trực tiếp trong process Python của bạn.\n",
    "\n",
    "## Đặc trưng:\n",
    "\n",
    "Binding tool trực tiếp cho model.\n",
    "\n",
    "Gọi tool là nội bộ, không qua bất kỳ giao thức trung gian nào.\n",
    "\n",
    "Thích hợp cho workflow đơn giản, nhanh gọn, quản lý tool dễ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a651bac9-70de-4d2c-8c60-5ac8b108b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_6OM9HJfCRY83qbfJTAHf3B87', 'function': {'arguments': '{\"location\":\"Munich\"}', 'name': 'get_restaurant_recommendations'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 59, 'total_tokens': 78, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e9671cd8-2feb-4ee9-a180-b8e36b2216e9-0' tool_calls=[{'name': 'get_restaurant_recommendations', 'args': {'location': 'Munich'}, 'id': 'call_6OM9HJfCRY83qbfJTAHf3B87', 'type': 'tool_call'}] usage_metadata={'input_tokens': 59, 'output_tokens': 19, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  \n",
    "\n",
    "@tool\n",
    "def get_restaurant_recommendations(location: str):\n",
    "    \"\"\"Provides a list of top restaurant recommendations for a given location.\"\"\"\n",
    "    recommendations = {\n",
    "        \"munich\": [\"Hofbräuhaus\", \"Augustiner-Keller\", \"Tantris\"],\n",
    "        \"new york\": [\"Le Bernardin\", \"Eleven Madison Park\", \"Joe's Pizza\"],\n",
    "        \"paris\": [\"Le Meurice\", \"L'Ambroisie\", \"Bistrot Paul Bert\"],\n",
    "    }\n",
    "    return recommendations.get(location.lower(), [\"No recommendations available for this location.\"])\n",
    "\n",
    "\n",
    "# TODO: Bind the tool to the model\n",
    "tools = [get_restaurant_recommendations]\n",
    "llm = ChatOpenAI()\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\"Recommend some restaurants in Munich.\")\n",
    "]\n",
    "\n",
    "#TODO: Invoke the llm\n",
    "llm_output = llm_with_tools.invoke(messages)\n",
    "print(llm_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9873dcc-c536-433f-ae83-e990d2703833",
   "metadata": {},
   "source": [
    "## 1. Cơ chế tool-calling của OpenAI (và LangChain)\n",
    "Khi bạn bind một tool vào LLM (như ChatOpenAI), model sẽ không trả về text trả lời thông thường (content), mà sẽ kích hoạt chế độ tool-calling nếu model xác định rằng prompt phù hợp với một tool đã bind.\n",
    "\n",
    "Lúc này, LLM không sinh ra “nội dung trả lời” cho người dùng, mà phát sinh một lệnh gọi tool với tham số phù hợp.\n",
    "\n",
    "## 2. Dấu hiệu trong kết quả trả về\n",
    "Trong additional_kwargs có trường tool_calls chứa thông tin:\n",
    "\n",
    "\"function\": {\"name\": \"get_restaurant_recommendations\", \"arguments\": '{\"location\":\"Munich\"}'}\n",
    "\n",
    "Tức là LLM đã chọn gọi tool này thay vì trả về content.\n",
    "\n",
    "Trường \"finish_reason\": \"tool_calls\" cũng xác nhận điều này.\n",
    "\n",
    "## 3. Tại sao lại thế?\n",
    "Design của API: Khi tool được gọi, content trả về luôn là rỗng (content='') — vì ý định của LLM là: “Tôi muốn hệ thống gọi tool này, sau đó lấy kết quả tool trả về để tiếp tục cuộc hội thoại.”\n",
    "\n",
    "Đáp án của model sẽ là một lệnh gọi tool, chứ chưa phải câu trả lời cuối cùng cho user.\n",
    "\n",
    "## 4. Luồng thực tế (tool-calling):\n",
    "Người dùng hỏi: Recommend some restaurants in Munich.\n",
    "\n",
    "LLM trả về:\n",
    "\n",
    "content = '' (rỗng)\n",
    "\n",
    "tool_calls = [{...get_restaurant_recommendations, args...}]\n",
    "\n",
    "Hệ thống thực hiện tool:\n",
    "\n",
    "Tool get_restaurant_recommendations(location=\"Munich\") được gọi trong Python.\n",
    "\n",
    "Trả về: danh sách nhà hàng.\n",
    "\n",
    "(Nếu muốn có content cuối cùng):\n",
    "\n",
    "Bạn cần tiếp tục đưa kết quả tool trả về vào LLM để model tổng hợp thành câu trả lời cho người dùng.\n",
    "\n",
    "## 5. Ý nghĩa thực tiễn\n",
    "content='' là bình thường trong quy trình tool-calling.\n",
    "\n",
    "Kết quả cuối cùng gửi cho user chỉ có sau khi tool được gọi xong, và (nếu cần) kết hợp lại với LLM để model viết ra nội dung trả lời.\n",
    "\n",
    "## Tóm lại:\n",
    "Khi LLM muốn gọi tool, trường content sẽ rỗng vì model nhường quyền trả lời cho tool — chỉ sau khi tool chạy xong, bạn mới có thể lấy nội dung ý nghĩa cho user nếu cần."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
